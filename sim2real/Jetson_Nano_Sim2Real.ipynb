{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "path_video_out = '/media/kimbring2/Steam/sim2real/raw_video.avi'\n",
    "video_out = cv2.VideoWriter(path_video_out, cv2.VideoWriter_fourcc(*'DIVX'), 20, (640,360))\n",
    "\n",
    "imported_seg = tf.saved_model.load(\"/media/kimbring2/Steam/sim2real/segmentation_model\")\n",
    "imported_gan = tf.saved_model.load(\"/media/kimbring2/Steam/sim2real/cyclegan_model\")\n",
    "\n",
    "f_seg = imported_seg.signatures[\"serving_default\"]\n",
    "f_gan = imported_gan.signatures[\"serving_default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seg_test_result.shape: (256, 256, 3)\n",
      "gan_test_result.shape: (256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "seg_test_input = np.zeros([1,256,256,3])\n",
    "gan_test_input = np.zeros([1,256,256,3])\n",
    "#style_test_input = np.zeros([1,256,256,3])\n",
    "\n",
    "seg_test_tensor = tf.convert_to_tensor(seg_test_input, dtype=tf.float32)\n",
    "gan_test_tensor = tf.convert_to_tensor(gan_test_input, dtype=tf.float32)\n",
    "\n",
    "seg_test_result = f_seg(seg_test_tensor)['conv2d_transpose_4'].numpy()[0]\n",
    "gan_test_result = f_gan(gan_test_tensor)['conv2d_transpose_7'].numpy()[0]\n",
    "\n",
    "print(\"seg_test_result.shape: \" + str(seg_test_result.shape))\n",
    "print(\"gan_test_result.shape: \" + str(gan_test_result.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = '/media/kimbring2/Steam/sim2real/content_image.jpg'\n",
    "test_image = cv2.imread(image_path)\n",
    "frame = test_image\n",
    "test_image = cv2.normalize(test_image, None, 0, 1, cv2.NORM_MINMAX, cv2.CV_32F)\n",
    "\n",
    "test_tensor = tf.convert_to_tensor(test_image, dtype=tf.float32)\n",
    "test_tensor = tf.image.resize(test_tensor, [256,256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "test_tensor = tf.reshape(test_tensor, [1,256,256,3], name=None)\n",
    "\n",
    "#pred_masks = model.predict(test_tensor)\n",
    "pred_mask = f_seg(test_tensor)['conv2d_transpose_4']\n",
    "pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "pred_mask = pred_mask[..., tf.newaxis]\n",
    "pred_mask = pred_mask[0]\n",
    "pred_mask = tf.keras.preprocessing.image.array_to_img(pred_mask)\n",
    "pred_mask = np.array(pred_mask)\n",
    "ret, thresh = cv2.threshold(pred_mask, 126, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "erudition_image = cv2.erode(thresh, kernel, iterations=2)  #// make dilation image\n",
    "dilation_image = cv2.dilate(erudition_image, kernel, iterations=2)  #// make dilation image\n",
    "dilation_image = cv2.resize(np.float32(dilation_image), dsize=(640,360), interpolation=cv2.INTER_AREA)\n",
    "plt.imshow(dilation_image)\n",
    "dilation_image = dilation_image != 255.0\n",
    "\n",
    "# converting from BGR to HSV color space\n",
    "hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Red color\n",
    "low_red = np.array([120, 155, 84])\n",
    "high_red = np.array([179, 255, 255])\n",
    "red_mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "red = cv2.bitwise_and(frame, frame, mask=red_mask)\n",
    "\n",
    "# Blue color\n",
    "low_blue = np.array([110, 130, 2])\n",
    "high_blue = np.array([126, 255, 255])\n",
    "blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "kernel = np.ones((10, 10), np.uint8)\n",
    "blue_mask = cv2.dilate(blue_mask, kernel, iterations=1)  #// make dilation image\n",
    "blue = cv2.bitwise_and(frame, frame, mask=blue_mask)\n",
    "\n",
    "# Green color\n",
    "low_green = np.array([25, 52, 72])\n",
    "high_green = np.array([60, 255, 255])\n",
    "green_mask = cv2.inRange(hsv_frame, low_green, high_green)\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "green_mask = cv2.dilate(green_mask, kernel, iterations=1)  #// make dilation image\n",
    "green = cv2.bitwise_and(frame, frame, mask=green_mask)\n",
    "\n",
    "mask = green_mask + blue_mask + dilation_image\n",
    "\n",
    "result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "result_mean = np.mean(result)\n",
    "\n",
    "for i in range(0, result.shape[0]):\n",
    "    for j in range(0, result.shape[1]):\n",
    "        if result[i,j,0] == 0 and result[i,j,1] == 0 and result[i,j,2] == 0:\n",
    "            result[i][j] = result_mean     \n",
    "            \n",
    "cv2.imwrite(\"/media/kimbring2/Steam/sim2real/image_seg.jpg\", result)\n",
    "            \n",
    "test_image = result\n",
    "test_image = (test_image / 127.5) - 1\n",
    "\n",
    "test_tensor = tf.convert_to_tensor(test_image, dtype=tf.float32)\n",
    "test_tensor = tf.image.resize(test_tensor, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "test_tensor = tf.reshape(test_tensor, [1,256,256,3], name=None)\n",
    "\n",
    "#generate_images(f_gan, test_tensor)\n",
    "prediction = f_gan(test_tensor)['conv2d_transpose_7'].numpy()\n",
    "\n",
    "gan_result = prediction[0]* 0.5 + 0.5\n",
    "gan_result = gan_result * 255\n",
    "\n",
    "#plt.imshow(gan_result)\n",
    "cv2.imwrite(\"/media/kimbring2/Steam/sim2real/image_gan.jpg\", gan_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret: True\n",
      "result.shape: (360, 640, 3)\n",
      "ret: True\n",
      "result.shape: (360, 640, 3)\n",
      "ret: True\n",
      "result.shape: (360, 640, 3)\n",
      "ret: True\n",
      "result.shape: (360, 640, 3)\n",
      "ret: True\n",
      "result.shape: (360, 640, 3)\n",
      "ret: True\n",
      "result.shape: (360, 640, 3)\n",
      "ret: True\n",
      "result.shape: (360, 640, 3)\n",
      "ret: True\n",
      "result.shape: (360, 640, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-0a71eaf611b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_dilation_video = '/home/kimbring2/Desktop/dilation_video.avi'\n",
    "path_segmented_video = '/home/kimbring2/Desktop/segmented_video.avi'\n",
    "\n",
    "dilation_video_out = cv2.VideoWriter(path_dilation_video, cv2.VideoWriter_fourcc(*'DIVX'), 5, (640,360))\n",
    "segmented_video_out = cv2.VideoWriter(path_segmented_video, cv2.VideoWriter_fourcc(*'DIVX'), 5, (640,360))\n",
    "\n",
    "cap = cv2.VideoCapture('/home/kimbring2/Desktop/image_real_3.avi')\n",
    "\n",
    "frame_index = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    print(\"ret: \" + str(ret))\n",
    "    if ret == True:\n",
    "        frame_index += 1\n",
    "        \n",
    "        test_image = cv2.normalize(test_image, None, 0, 1, cv2.NORM_MINMAX, cv2.CV_32F)\n",
    "        \n",
    "        test_tensor = tf.convert_to_tensor(test_image, dtype=tf.float32)\n",
    "        test_tensor = tf.image.resize(test_tensor, [256,256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        test_tensor = tf.reshape(test_tensor, [1,256,256,3], name=None)\n",
    "\n",
    "        #pred_masks = model.predict(test_tensor)\n",
    "        pred_mask = f_seg(test_tensor)['conv2d_transpose_4']\n",
    "        pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "        pred_mask = pred_mask[..., tf.newaxis]\n",
    "        pred_mask = pred_mask[0]\n",
    "        pred_mask = tf.keras.preprocessing.image.array_to_img(pred_mask)\n",
    "        pred_mask = np.array(pred_mask)\n",
    "        ret, thresh = cv2.threshold(pred_mask, 126, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        erudition_image = cv2.erode(thresh, kernel, iterations=2)  #// make dilation image\n",
    "        dilation_image = cv2.dilate(erudition_image, kernel, iterations=2)  #// make dilation image\n",
    "        dilation_image = cv2.resize(np.float32(dilation_image), dsize=(640,360), interpolation=cv2.INTER_AREA)\n",
    "        dilation_image_rgb = cv2.cvtColor(dilation_image, cv2.COLOR_GRAY2RGB)\n",
    "        #print(\"np.uint8(dilation_image_rgb).shape: \" + str(np.uint8(dilation_image_rgb).shape))\n",
    "        dilation_video_out.write(np.uint8(dilation_image_rgb))\n",
    "        \n",
    "        dilation_image = dilation_image != 255.0\n",
    "\n",
    "        # converting from BGR to HSV color space\n",
    "        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Red color\n",
    "        low_red = np.array([120, 155, 84])\n",
    "        high_red = np.array([179, 255, 255])\n",
    "        red_mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "        red = cv2.bitwise_and(frame, frame, mask=red_mask)\n",
    "\n",
    "        # Blue color\n",
    "        low_blue = np.array([110, 130, 2])\n",
    "        high_blue = np.array([126, 255, 255])\n",
    "        blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        blue_mask = cv2.dilate(blue_mask, kernel, iterations=1)  #// make dilation image\n",
    "        blue = cv2.bitwise_and(frame, frame, mask=blue_mask)\n",
    "\n",
    "        # Green color\n",
    "        low_green = np.array([25, 52, 72])\n",
    "        high_green = np.array([60, 255, 255])\n",
    "        green_mask = cv2.inRange(hsv_frame, low_green, high_green)\n",
    "        kernel = np.ones((5, 5), np.uint8)\n",
    "        green_mask = cv2.dilate(green_mask, kernel, iterations=1)  #// make dilation image\n",
    "        green = cv2.bitwise_and(frame, frame, mask=green_mask)\n",
    "\n",
    "        mask = green_mask + blue_mask + dilation_image\n",
    "\n",
    "        result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "        result_mean = np.mean(result)\n",
    "\n",
    "        print(\"result.shape: \" + str(result.shape))\n",
    "        segmented_video_out.write(result)\n",
    "        \n",
    "        for i in range(0, result.shape[0]):\n",
    "            for j in range(0, result.shape[1]):\n",
    "                if result[i,j,0] == 0 and result[i,j,1] == 0 and result[i,j,2] == 0:\n",
    "                    result[i][j] = result_mean     \n",
    "\n",
    "        test_image = result\n",
    "        test_image = (test_image / 127.5) - 1\n",
    "\n",
    "        test_tensor = tf.convert_to_tensor(test_image, dtype=tf.float32)\n",
    "        test_tensor = tf.image.resize(test_tensor, [256, 256], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        test_tensor = tf.reshape(test_tensor, [1,256,256,3], name=None)\n",
    "\n",
    "        #generate_images(f_gan, test_tensor)\n",
    "        prediction = f_gan(test_tensor)['conv2d_transpose_7'].numpy()\n",
    "\n",
    "        gan_result = prediction[0]* 0.5 + 0.5\n",
    "        gan_result = gan_result * 255\n",
    "        #cv2.imwrite(\"/home/kimbring2/Desktop/result_image/image_\" + str(frame_index) + \".jpg\", gan_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysc2_env",
   "language": "python",
   "name": "pysc2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
